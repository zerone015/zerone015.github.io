---
title: "CPU Cache"
date: 2026-01-22 20:00:00 +0900
categories: [CS]
tags: [cache]
math: true
---

## Definition
CPU 내부에 있는 SRAM을 말한다. 메인 메모리(DRAM)는 CPU 연산 속도에 비해 너무 느리기 때문에 데이터 병목 현상이 발생한다. 이 병목을 완화하기 위해 CPU와 메인 메모리 사이에 SRAM이라는 작고 빠른 캐시를 두게 되었다.

## Locality of Reference
캐시는 지역성(Locality)의 원리를 이용해 동작한다.
* **Temporal Locality (시간 지역성):** 최근에 사용된 데이터는 가까운 미래에 재사용될 가능성이 높다.
* **Spatial Locality (공간 지역성):** 접근한 데이터의 근처 데이터는 가까운 미래에 사용될 가능성이 높다.

## Cache Line
메인 메모리에서 캐시로 데이터를 가져올 때, 공간 지역성을 활용하기 위해 접근한 데이터 단위가 아닌 더 큰 단위로 가져온다. 이를 캐시라인이라 하며 대부분의 시스템에서 64B 크기를 갖는다. 캐시라인은 캐시가 데이터를 관리하는 최소 단위이다.

## Cache Hierarchy
현대 시스템은 더 빠른 성능을 위해 여러 단계의 캐시 계층을 갖는다. (L1, L2, L3 캐시) CPU 코어와 가까울수록 속도가 빠르고 용량이 작다.

## Mapping Strategies
물리 메모리 주소로 특정 캐시라인을 찾기 위해 주소 비트는 Tag, Index, Offset 세 부분으로 나뉜다. 각 캐시라인에는 데이터 외에도 태그 값과 해당 라인의 유효성을 나타내는 Valid bit 등이 저장된다.

### 1. Direct Mapped Cache
물리 메모리의 특정 주소 데이터는 정해진 캐시라인에만 들어갈 수 있다.
* **특징:** 탐색할 필요가 없어 빠르지만, 위치가 고정되어 있어 동일한 인덱스를 갖는 메모리 주소들이 부딪히는 충돌 미스가 잦다.
* **비트 계산:**
    * **Index:** $log_2(\text{전체 캐시 크기} / \text{캐시라인 크기})$
    * **Offset:** $log_2(\text{캐시라인 크기})$
    * **Tag:** 전체 주소 비트 - (Index + Offset)

### 2. Fully Associative Cache
물리 메모리의 어떤 데이터도 캐시 내의 어떤 라인에든 들어갈 수 있다.
* **특징:** 충돌이 거의 없어 히트율이 높다. 하지만 원하는 데이터를 찾으려면 모든 캐시라인의 태그를 병렬적으로 탐색해야 하므로 캐시라인 개수만큼의 Comparator가 필요하다. 전력 소모가 크고 회로가 복잡하다.
* **비트 계산:**
    * **Index:** 사용되지 않음.
    * **Offset:** $log_2(\text{캐시라인 크기})$
    * **Tag:** 전체 주소 비트 - Offset

### 3. Set Associative Cache
직접 사상과 완전 연관 사상의 트레이드오프 방식이다.
* **특징:** 전체 캐시는 세트 단위로 나뉜다. 특정 주소는 정해진 세트에만 들어갈 수 있지만, 세트 내의 여러 라인 중 하나를 자유롭게 선택할 수 있다. 직접 사상보다 충돌이 적고 완전 연관 사상보다 하드웨어 비용이 적다. 현대 CPU 캐시의 표준 방식이다.
* **비트 계산:**
    * **Index:** $log_2(\text{전체 캐시 크기} / \text{캐시라인 크기} / \text{세트당 캐시라인 개수})$
    * **Offset:** $log_2(\text{캐시라인 크기})$
    * **Tag:** 전체 주소 비트 - (Index + Offset)

## Replacement Policy
캐시 세트가 가득 찼을 때 어떤 라인을 비울지 결정하는 알고리즘이다.
* **LRU (Least Recently Used):** 가장 오랫동안 사용되지 않은 라인을 교체한다. 이론적으로 우수하지만 구현 비용이 크다.
* **Pseudo-LRU:** 트리나 비트를 이용해 LRU와 유사하게 동작하도록 만든 효율적인 방식이다. 실제 현대 CPU에서 주로 사용한다.
* **Random:** 무작위로 교체하며 구현이 단순하다.

## Write Policy
수정된 데이터를 메인 메모리에 반영하는 시점을 결정한다.
* **Write-through:** 캐시와 메모리를 동시에 업데이트한다. 데이터 일관성이 보장되나 성능이 느리다.
* **Write-back:** 캐시만 먼저 수정하고, 해당 라인이 교체될 때 메모리에 기록한다. Dirty bit를 사용하며 성능이 빠르다. 다만 멀티코어 환경에서는 코어 간 데이터 불일치 문제를 야기하므로 별도의 일관성 프로토콜이 필요하다.
